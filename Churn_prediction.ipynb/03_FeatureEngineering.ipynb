{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='text-align:center'>Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created 'preprocess' function in DataCleaning step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_preprocessing\n",
    "\n",
    "def preprocess(dataset:pd.DataFrame) -> pd.DataFrame :\n",
    "    '''\n",
    "    dataset contain this columns:\n",
    "        'gender':               ['Female' 'Male']\n",
    "        'SeniorCitizen':        [0 1]\n",
    "        'Partner':              ['Yes' 'No']\n",
    "        'Dependents':           ['No' 'Yes']\n",
    "        'tenure':               int\n",
    "        'PhoneService':         ['No' 'Yes']\n",
    "        'MultipleLines':        ['No phone service' 'No' 'Yes']\n",
    "        'InternetService':      ['DSL' 'Fiber optic' 'No']\n",
    "        'OnlineSecurity':       ['No' 'Yes' 'No internet service']\n",
    "        'OnlineBackup':         ['Yes' 'No' 'No internet service']\n",
    "        'DeviceProtection':     ['No' 'Yes' 'No internet service']\n",
    "        'TechSupport':          ['No' 'Yes' 'No internet service']\n",
    "        'StreamingTV':          ['No' 'Yes' 'No internet service']\n",
    "        'StreamingMovies':      ['No' 'Yes' 'No internet service']\n",
    "        'Contract':             ['Month-to-month' 'One year' 'Two year']\n",
    "        'PaperlessBilling':     ['Yes' 'No']\n",
    "        'PaymentMethod':        ['Electronic check' 'Mailed check' 'Bank transfer (automatic)' 'Credit card (automatic)']\n",
    "        'MonthlyCharges':       float\n",
    "        'TotalCharges':         float\n",
    "        'Churn':                ['No' 'Yes']   // Not necessary\n",
    "    '''\n",
    "    df = dataset.copy()\n",
    "\n",
    "    # Prepare string variables\n",
    "    df.columns = df.columns.str.lower().str.replace(' ','_')\n",
    "    string_columns = list(df.dtypes[df.dtypes=='O'].index)\n",
    "    for col in string_columns:\n",
    "        df[col] = df[col].str.lower().str.replace(' ','_')\n",
    "\n",
    "    # drop customerid\n",
    "    if 'customerid' in df.columns:\n",
    "        del df['customerid']\n",
    "        \n",
    "    # Prepare numeric columns type\n",
    "    if 'tenure' in df.columns:\n",
    "        df['tenure'] = pd.to_numeric(df['tenure'], errors='coerce')\n",
    "        df['tenure'] = df['tenure'].fillna(0)\n",
    "    else:\n",
    "        raise Exception(\"!!! Tenure column didn't exist !!!\")\n",
    "\n",
    "    if 'monthlycharges' in df.columns:\n",
    "        df['monthlycharges'] = pd.to_numeric(df['monthlycharges'], errors='coerce')\n",
    "        df['monthlycharges'] = df['monthlycharges'].fillna(0)\n",
    "    else:\n",
    "        raise Exception(\"!!! MonthlyCharges column didn't exist !!!\")\n",
    "\n",
    "    if 'totalcharges' in df.columns:\n",
    "        df['totalcharges'] = pd.to_numeric(df['totalcharges'], errors='coerce')\n",
    "        df['totalcharges'] = df['totalcharges'].fillna(0)\n",
    "    else:\n",
    "        raise Exception(\"!!! TotalCharges column didn't exist !!!\")\n",
    "        \n",
    "    # Make dependent variable numeric\n",
    "    if 'churn' in df.columns:\n",
    "        df.churn = (df.churn == 'yes').astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_prediction.csv')\n",
    "df = preprocess(df)\n",
    "\n",
    "categorical_important=['contract', 'onlinesecurity', 'techsupport', 'internetservice']\n",
    "numerical_important = ['tenure', 'monthlycharges', 'totalcharges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Split dataset to <u>training set</u> and <u>test set</u></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='color:red; text-align:center'>It's so important to split the dataset before scaling or encoding it.<br>\n",
    "cause the training dataset shouldn't affect the test set values.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[:,df.columns!='churn'],\n",
    "                                                    df['churn'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contract</th>\n",
       "      <th>onlinesecurity</th>\n",
       "      <th>techsupport</th>\n",
       "      <th>internetservice</th>\n",
       "      <th>tenure</th>\n",
       "      <th>monthlycharges</th>\n",
       "      <th>totalcharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>two_year</td>\n",
       "      <td>no_internet_service</td>\n",
       "      <td>no_internet_service</td>\n",
       "      <td>no</td>\n",
       "      <td>12</td>\n",
       "      <td>19.70</td>\n",
       "      <td>258.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5946</th>\n",
       "      <td>one_year</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>dsl</td>\n",
       "      <td>42</td>\n",
       "      <td>73.90</td>\n",
       "      <td>3160.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>two_year</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>dsl</td>\n",
       "      <td>71</td>\n",
       "      <td>65.15</td>\n",
       "      <td>4681.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>one_year</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>dsl</td>\n",
       "      <td>71</td>\n",
       "      <td>85.45</td>\n",
       "      <td>6300.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>one_year</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>dsl</td>\n",
       "      <td>30</td>\n",
       "      <td>70.40</td>\n",
       "      <td>2044.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>month-to-month</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>fiber_optic</td>\n",
       "      <td>9</td>\n",
       "      <td>100.50</td>\n",
       "      <td>918.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>two_year</td>\n",
       "      <td>no_internet_service</td>\n",
       "      <td>no_internet_service</td>\n",
       "      <td>no</td>\n",
       "      <td>60</td>\n",
       "      <td>19.95</td>\n",
       "      <td>1189.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>month-to-month</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>fiber_optic</td>\n",
       "      <td>28</td>\n",
       "      <td>105.70</td>\n",
       "      <td>2979.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>month-to-month</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>dsl</td>\n",
       "      <td>2</td>\n",
       "      <td>54.40</td>\n",
       "      <td>114.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>two_year</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>dsl</td>\n",
       "      <td>16</td>\n",
       "      <td>68.25</td>\n",
       "      <td>1114.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5634 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            contract       onlinesecurity          techsupport  \\\n",
       "1814        two_year  no_internet_service  no_internet_service   \n",
       "5946        one_year                  yes                  yes   \n",
       "3881        two_year                  yes                  yes   \n",
       "2389        one_year                  yes                  yes   \n",
       "3676        one_year                  yes                  yes   \n",
       "...              ...                  ...                  ...   \n",
       "905   month-to-month                   no                   no   \n",
       "5192        two_year  no_internet_service  no_internet_service   \n",
       "3980  month-to-month                   no                   no   \n",
       "235   month-to-month                   no                   no   \n",
       "5157        two_year                  yes                  yes   \n",
       "\n",
       "     internetservice  tenure  monthlycharges  totalcharges  \n",
       "1814              no      12           19.70        258.35  \n",
       "5946             dsl      42           73.90       3160.55  \n",
       "3881             dsl      71           65.15       4681.75  \n",
       "2389             dsl      71           85.45       6300.85  \n",
       "3676             dsl      30           70.40       2044.75  \n",
       "...              ...     ...             ...           ...  \n",
       "905      fiber_optic       9          100.50        918.60  \n",
       "5192              no      60           19.95       1189.90  \n",
       "3980     fiber_optic      28          105.70       2979.50  \n",
       "235              dsl       2           54.40        114.10  \n",
       "5157             dsl      16           68.25       1114.85  \n",
       "\n",
       "[5634 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[categorical_important+numerical_important]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the working directory path to save in the Future.<br>\n",
    "I will save mean and std values of standardizing in a CSV file to use in the future or I will save OneHotEncoding important values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "\n",
    "# we create a folder to save our data there \n",
    "assets_path = path+'\\\\assets'\n",
    "if not os.path.exists(assets_path):\n",
    "    os.makedirs(assets_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>OneHotEncoding</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We just use this function for training dataset \n",
    "def ohe(dataset:pd.DataFrame, categorical_columns:str):\n",
    "    df = dataset.copy()\n",
    "    df_info = pd.DataFrame(columns=['col', 'uniques'])\n",
    "    for col in categorical_columns:\n",
    "        list_Uniques = df[col].unique()\n",
    "        df_info.loc[len(df_info)] = [col, ','.join(map(str, list_Uniques))]\n",
    "        for name in list_Uniques:\n",
    "            df[str(col)+'_'+str(name)] = df[col].apply(lambda x : 1 if x==name else 0)\n",
    "        del df[col]\n",
    "\n",
    "    df_info.to_csv(assets_path+'\\\\ohe_info.csv', index=False)\n",
    "    return df\n",
    "\n",
    "df=ohe(df, categorical_important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use code below for test dataset.\n",
    "\n",
    "# df_info = pd.read_csv(assets_path+'\\\\ohe_info.csv')\n",
    "# for i in range(len(df_info)):\n",
    "    # col = df_info.iloc[i,:].col\n",
    "    # list_Uniques = df_info.iloc[i,:].uniques.split(',')\n",
    "    # for name in list_Uniques:\n",
    "        # df[str(col)+'_'+str(name)] =  df[col].apply(lambda x : 1 if x==name else 0)\n",
    "    # del df[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature scaling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for training dataset\n",
    "scale_info = pd.DataFrame(columns=['col','mean','std'])\n",
    "for col in numerical_important:\n",
    "    mean_col = df[col].mean()\n",
    "    std_col = df[col].std()\n",
    "    df[col] = (df[col]-mean_col)/std_col\n",
    "    scale_info.loc[len(scale_info)] = [col, mean_col, std_col]\n",
    "\n",
    "scale_info.to_csv(assets_path+'\\\\scale_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for test dataset\n",
    "\n",
    "# scale_info = pd.read_csv(assets_path+'\\\\scale_info.csv')\n",
    "\n",
    "# for i in range(len(scale_info)):\n",
    "#     col = scale_info.loc[i,'col']\n",
    "#     mean_col = scale_info.loc[i,'mean']\n",
    "#     std_col = scale_info.loc[i,'std']\n",
    "#     df[col] = (df[col]-mean_col)/std_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "package all of the feature engineering functions in a function to use for each training dataset and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureEngineering(dataset:pd.DataFrame,\n",
    "                       categorical_variables:list,\n",
    "                       numerical_variables:list,\n",
    "                       isTrain:bool,\n",
    "                       scaleColumns:list):\n",
    "    \"\"\"\n",
    "    dataset: pd.Dataframe\n",
    "    categorical_variables: list of important categorical columns that we want to use in pur model\n",
    "    numerical_variables: list of important numerical columns that we want to use in pur model\n",
    "    isTrain:    if you want to train a model, set it 'True'\n",
    "                if you want to use for test or deployment set it 'False'\n",
    "    \"\"\"\n",
    "    df = dataset.copy()\n",
    "    categorical_important = categorical_variables.copy()\n",
    "    numerical_important = numerical_variables.copy()\n",
    "    df = df[numerical_important + categorical_important]\n",
    "\n",
    "    # we create a folder to save our data there \n",
    "    path = os.getcwd()\n",
    "    assets_path = path+'\\\\assets'\n",
    "    if not os.path.exists(assets_path):\n",
    "        os.makedirs(assets_path)\n",
    "\n",
    "    # Dummy variables\n",
    "    if isTrain:\n",
    "        def ohe(dataset:pd.DataFrame, categorical_columns:str):\n",
    "            df = dataset.copy()\n",
    "            df_info = pd.DataFrame(columns=['col', 'uniques'])\n",
    "            for col in categorical_columns:\n",
    "                list_Uniques = df[col].unique()\n",
    "                df_info.loc[len(df_info)] = [col, ','.join(map(str, list_Uniques))]\n",
    "                for name in list_Uniques:\n",
    "                    df[str(col)+'_'+str(name)] = df[col].apply(lambda x : 1 if x==name else 0)\n",
    "                del df[col]\n",
    "\n",
    "            df_info.to_csv(assets_path'\\\\ohe_info.csv', index=False)\n",
    "            return df\n",
    "\n",
    "        df=ohe(df, categorical_important)\n",
    "    else:\n",
    "        df_info = pd.read_csv(assets_path+'\\ohe_info.csv')\n",
    "        for i in range(len(df_info)):\n",
    "            col = df_info.iloc[i,:].col\n",
    "            list_Uniques = df_info.iloc[i,:].uniques.split(',')\n",
    "            for name in list_Uniques:\n",
    "                df[str(col)+'_'+str(name)] =  df[col].apply(lambda x : 1 if x==name else 0)\n",
    "            del df[col]\n",
    "\n",
    "    # Feature scaling\n",
    "    if isTrain:\n",
    "        scale_info = pd.DataFrame(columns=['col','mean','std'])\n",
    "        for col in scaleColumns:\n",
    "            mean_col = df[col].mean()\n",
    "            std_col = df[col].std()\n",
    "            df[col] = (df[col]-mean_col)/std_col\n",
    "            scale_info.loc[len(scale_info)] = [col, mean_col, std_col]\n",
    "        \n",
    "        scale_info.to_csv(assets_path+'\\\\scale_info.csv', index=False)\n",
    "    else:\n",
    "        scale_info = pd.read_csv(assets_path+'\\\\scale_info.csv')\n",
    "        \n",
    "        for i in range(len(scale_info)):\n",
    "            col = scale_info.loc[i,'col']\n",
    "            mean_col = scale_info.loc[i,'mean']\n",
    "            std_col = scale_info.loc[i,'std']\n",
    "\n",
    "            df[col] = (df[col]-mean_col)/std_col\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aafc33a19d1e6c143b5a4b283b91d6d8d620b2aadbd9675105175468fd18e65b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
